{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Face detection using dataset**"
      ],
      "metadata": {
        "id": "trI9FCtk8zl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "os.environ['KAGGLE_USERNAME'] = \"dipali2109\"\n",
        "os.environ['KAGGLE_KEY'] = \"7e254bc376de0d7b79f06b6fa269cc7c\"\n",
        "\n",
        "!kaggle datasets download imrankhan77/autistic-children-facial-data-set\n",
        "\n",
        "!unzip /content/autistic-children-facial-data-set.zip\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Function to detect face in an image\n",
        "def detect_face(image_path, face_cascade):\n",
        "  img = cv2.imread(image_path)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "  return [(x,y,w,h) for (x,y,w,h) in faces]\n",
        "\n",
        "# Function to extract face from an image\n",
        "def extract_face(image_path, face_cascade):\n",
        "  faces = detect_face(image_path, face_cascade)\n",
        "  if len(faces) == 0:\n",
        "    return None\n",
        "  img = cv2.imread(image_path)\n",
        "  x,y,w,h = faces[0]\n",
        "  face_img = img[x:x + w, y:y + h]\n",
        "  return face_img\n",
        "\n",
        "# Function to prepare data: load, detect and extract\n",
        "def prepare_data(data_directory, face_cascade):\n",
        "  labels = []\n",
        "  faces = []\n",
        "  label_names = os.listdir(data_directory)\n",
        "  for label_name in label_names:\n",
        "    label_dir = os.path.join(data_directory, label_name)\n",
        "    for img_name in os.listdir(label_dir):\n",
        "      img_dir = os.path.join(label_dir, img_name)\n",
        "      face_img = extract_face(img_dir, face_cascade)\n",
        "      if face_img is not None:\n",
        "        faces.append(cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY))\n",
        "        labels.append(label_name)\n",
        "\n",
        "  return faces, labels, label_names\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "data_directory = '/content/train'\n",
        "faces, labels, label_names = prepare_data(data_directory, face_cascade)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "recognizer.train(faces, np.array(encoded_labels))\n",
        "\n",
        "def recognize_face(image_path, recognizer, face_cascade, label_encoder):\n",
        "  face_img = extract_face(image_path, face_cascade)\n",
        "  if face_img is not None:\n",
        "    gray_image = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
        "    label, confidence = recognizer.predict(gray_image)\n",
        "    name = label_encoder.inverse_transform([label])[0]\n",
        "    return name, confidence\n",
        "  return None, None\n",
        "\n",
        "image_path = '/content/Sad_Person.jpeg'\n",
        "name, confidence = recognize_face(image_path, recognizer, face_cascade, label_encoder)\n",
        "print(f\"Predicted name: {name}, Confidence: {confidence}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Initialize face detector\n",
        "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Start video capture\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    # Detect faces and draw rectangles\n",
        "    faces = faceCascade.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), 1.1, 5)\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Face Detection', frame)\n",
        "\n",
        "    # Exit on pressing 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "F2EEATs986Uk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyMsn6oL86lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face detection using webcam**"
      ],
      "metadata": {
        "id": "Vz0xcQbi9CKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Initialize face detector\n",
        "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Start video capture\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    # Detect faces and draw rectangles\n",
        "    faces = faceCascade.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), 1.1, 5)\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Face Detection', frame)\n",
        "\n",
        "    # Exit on pressing 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "fZudzy8M86n4",
        "outputId": "ff09dbc8-bf11-4bca-a61e-eed343bce8de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fac6f1b328e3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Detect faces and draw rectangles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaceCascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkC64oLg86p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6Q0G3qV86td"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}